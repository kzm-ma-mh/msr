"""
RAG Engine
ØªØ±Ú©ÛŒØ¨ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ (ChromaDB) Ø¨Ø§ ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® (LLM)
"""

import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
from config import Config
from llm_client import LLMClient


class RAGEngine:
    def __init__(self):
        print("\nğŸ§  Initializing RAG Engine...")

        # â”€â”€â”€ Embedding Model â”€â”€â”€
        print(f"   ğŸ“¦ Loading embedding model: {Config.EMBEDDING_MODEL}")
        self.embedder = SentenceTransformer(Config.EMBEDDING_MODEL)
        print(f"   âœ… Embedding loaded (dim: {self.embedder.get_sentence_embedding_dimension()})")

        # â”€â”€â”€ ChromaDB â”€â”€â”€
        print(f"   ğŸ—„ï¸  Connecting to ChromaDB: {Config.CHROMA_PERSIST_DIR}")
        self.chroma_client = chromadb.PersistentClient(
            path=Config.CHROMA_PERSIST_DIR,
            settings=Settings(anonymized_telemetry=False),
        )

        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ collections
        self.collections = {}
        collection_map = {
            "code": Config.COLLECTION_CODE,
            "issue": Config.COLLECTION_ISSUES,
            "pull_request": Config.COLLECTION_PRS,
            "commit": Config.COLLECTION_COMMITS,
        }

        for key, name in collection_map.items():
            try:
                col = self.chroma_client.get_collection(name)
                self.collections[key] = col
                print(f"      âœ… {key}: {col.count()} documents")
            except Exception:
                print(f"      âš ï¸ {key}: not found")

        # â”€â”€â”€ LLM â”€â”€â”€
        self.llm = LLMClient()
        self.llm.check_connection()

        print("\n   âœ… RAG Engine ready!")

    # â”€â”€â”€ Embedding â”€â”€â”€

    def _embed(self, text):
        """ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø¨Ù‡ Ø¨Ø±Ø¯Ø§Ø±"""
        embedding = self.embedder.encode(
            [text],
            normalize_embeddings=True,
            show_progress_bar=False,
        )
        return embedding.tolist()[0]

    # â”€â”€â”€ Retrieve â”€â”€â”€

    def retrieve(self, query, collections=None, top_k=None, score_threshold=None):
        """
        Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø³Ù†Ø§Ø¯ Ù…Ø±ØªØ¨Ø·

        Args:
            query: Ø³ÙˆØ§Ù„ Ú©Ø§Ø±Ø¨Ø±
            collections: Ù„ÛŒØ³Øª collection Ù‡Ø§ (None = Ù‡Ù…Ù‡)
            top_k: ØªØ¹Ø¯Ø§Ø¯ Ù†ØªØ§ÛŒØ¬
            score_threshold: Ø­Ø¯Ø§Ù‚Ù„ score

        Returns:
            list[dict]: Ù†ØªØ§ÛŒØ¬ Ù…Ø±ØªØ¨ Ø´Ø¯Ù‡
        """
        if top_k is None:
            top_k = Config.RAG_TOP_K
        if score_threshold is None:
            score_threshold = Config.RAG_SCORE_THRESHOLD

        query_embedding = self._embed(query)

        # Ø§Ú¯Ù‡ collection Ù…Ø´Ø®Øµ Ù†Ø´Ø¯Ù‡ â†’ Ù‡Ù…Ù‡
        if collections is None:
            target_collections = list(self.collections.keys())
        else:
            target_collections = collections

        all_results = []

        for col_name in target_collections:
            collection = self.collections.get(col_name)
            if not collection or collection.count() == 0:
                continue

            try:
                n = min(top_k, collection.count())
                results = collection.query(
                    query_embeddings=[query_embedding],
                    n_results=n,
                    include=["documents", "metadatas", "distances"],
                )

                if not results or not results.get("documents"):
                    continue

                docs = results["documents"][0]
                metas = results["metadatas"][0]
                dists = results["distances"][0]

                for doc, meta, dist in zip(docs, metas, dists):
                    score = round(1 - dist, 4)
                    if score >= score_threshold:
                        all_results.append({
                            "content": doc,
                            "metadata": meta,
                            "collection": col_name,
                            "score": score,
                        })

            except Exception as e:
                print(f"   âš ï¸ Search error in {col_name}: {e}")

        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ score
        all_results.sort(key=lambda x: x["score"], reverse=True)

        return all_results[:top_k]

    # â”€â”€â”€ Context Building â”€â”€â”€

    def build_context(self, results):
        """
        Ø³Ø§Ø®Øª context Ø§Ø² Ù†ØªØ§ÛŒØ¬ Ø¬Ø³ØªØ¬Ùˆ

        Args:
            results: Ø®Ø±ÙˆØ¬ÛŒ retrieve

        Returns:
            str: Ù…ØªÙ† context
        """
        if not results:
            return ""

        context_parts = []
        total_length = 0

        for i, result in enumerate(results, 1):
            meta = result["metadata"]
            collection = result["collection"]
            score = result["score"]

            # Ù‡Ø¯Ø±
            header = f"[Source {i} | {collection} | relevance: {score}]"

            if collection == "code":
                header += f"\nFile: {meta.get('file_path', 'unknown')}"
                header += f" (Language: {meta.get('language', 'unknown')})"
            elif collection == "issue":
                header += f"\nIssue #{meta.get('issue_number', '?')}: {meta.get('title', '')}"
                header += f" (State: {meta.get('state', 'unknown')})"
            elif collection == "pull_request":
                header += f"\nPR #{meta.get('pr_number', '?')}: {meta.get('title', '')}"
                status = "Merged" if meta.get("merged") else meta.get("state", "unknown")
                header += f" (Status: {status})"
            elif collection == "commit":
                header += f"\nCommit {meta.get('sha', '?')}: {meta.get('message', '')}"

            section = f"{header}\n{result['content']}"

            # Ú†Ú© Ø·ÙˆÙ„ Ú©Ù„
            if total_length + len(section) > Config.RAG_MAX_CONTEXT_LENGTH:
                remaining = Config.RAG_MAX_CONTEXT_LENGTH - total_length - 100
                if remaining > 200:
                    section = section[:remaining] + "\n... (truncated)"
                    context_parts.append(section)
                break

            context_parts.append(section)
            total_length += len(section)

        return "\n\n---\n\n".join(context_parts)

    # â”€â”€â”€ Prompt Building â”€â”€â”€

    def build_prompt(self, query, context):
        """Ø³Ø§Ø®Øª prompt Ù†Ù‡Ø§ÛŒÛŒ"""
        if context:
            prompt = f"""Based on the following context from the repository, answer the user's question.

## Context:
{context}

## Question:
{query}

## Instructions:
- Use the context above to provide an accurate answer
- Reference specific files, issues, or PRs when relevant
- Provide code examples when appropriate
- If the context doesn't contain enough information, say so

## Answer:"""
        else:
            prompt = f"""Answer the following question about the repository.
Note: No relevant context was found in the repository for this question.

## Question:
{query}

## Answer:"""

        return prompt

    # â”€â”€â”€ Build Sources â”€â”€â”€

    def _build_sources(self, results):
        """Ø³Ø§Ø®Øª Ù„ÛŒØ³Øª sources Ø§Ø² Ù†ØªØ§ÛŒØ¬"""
        sources = []
        for r in results:
            source = {
                "type": r["collection"],
                "score": r["score"],
            }
            meta = r["metadata"]

            if r["collection"] == "code":
                source["file"] = meta.get("file_path", "")
            elif r["collection"] == "issue":
                source["issue_number"] = meta.get("issue_number", 0)
                source["title"] = meta.get("title", "")
            elif r["collection"] == "pull_request":
                source["pr_number"] = meta.get("pr_number", 0)
                source["title"] = meta.get("title", "")
            elif r["collection"] == "commit":
                source["sha"] = meta.get("sha", "")
                source["message"] = meta.get("message", "")

            sources.append(source)

        return sources

    # â”€â”€â”€ Main Query â”€â”€â”€

    def query(self, question, collections=None, top_k=None, temperature=0.7):
        """
        Ø³ÙˆØ§Ù„ Ø§Ø² RAG

        Args:
            question: Ø³ÙˆØ§Ù„ Ú©Ø§Ø±Ø¨Ø±
            collections: ÙÛŒÙ„ØªØ± collection Ù‡Ø§
            top_k: ØªØ¹Ø¯Ø§Ø¯ context
            temperature: Ø®Ù„Ø§Ù‚ÛŒØª LLM

        Returns:
            dict: {answer, sources, context_length, sources_count}
        """
        # Û±. Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ
        results = self.retrieve(question, collections=collections, top_k=top_k)

        # Û². Ø³Ø§Ø®Øª context
        context = self.build_context(results)

        # Û³. Ø³Ø§Ø®Øª prompt
        prompt = self.build_prompt(question, context)

        # Û´. ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®
        answer = self.llm.generate(prompt, temperature=temperature)

        # Ûµ. Ø³Ø§Ø®Øª sources
        sources = self._build_sources(results)

        return {
            "answer": answer,
            "sources": sources,
            "context_length": len(context),
            "sources_count": len(sources),
        }

    def query_stream(self, question, collections=None, top_k=None, temperature=0.7):
        """
        Ø³ÙˆØ§Ù„ Ø§Ø² RAG Ø¨ØµÙˆØ±Øª streaming

        Yields:
            dict: {type: "sources"|"token"|"done", data: ...}
        """
        # Û±. Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ
        results = self.retrieve(question, collections=collections, top_k=top_k)

        # Û². Ø§Ø±Ø³Ø§Ù„ sources
        sources = self._build_sources(results)
        yield {"type": "sources", "data": sources}

        # Û³. Ø³Ø§Ø®Øª context Ùˆ prompt
        context = self.build_context(results)
        prompt = self.build_prompt(question, context)

        # Û´. Stream tokens
        for token in self.llm.generate_stream(prompt, temperature=temperature):
            yield {"type": "token", "data": token}

        yield {"type": "done", "data": None}

    # â”€â”€â”€ Stats â”€â”€â”€

    def get_stats(self):
        """Ø¢Ù…Ø§Ø± RAG Engine"""
        stats = {
            "llm_model": Config.OLLAMA_MODEL,
            "llm_provider": Config.LLM_PROVIDER,
            "embedding_model": Config.EMBEDDING_MODEL,
            "collections": {},
            "total_documents": 0,
        }

        for name, col in self.collections.items():
            count = col.count()
            stats["collections"][name] = count
            stats["total_documents"] += count

        return stats